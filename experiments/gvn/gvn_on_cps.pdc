%GVN on CPS
%
%

<!-- TODO: bib, cites -->

Global Value Numbering (GVN) is an optimisation algorithm that takes advantage
of the Single Static Assignment (SSA) form to improve on Value Numbering.

Continuation Passing Style (CPS) is a special form of $\lambda$-calculus where
functions get a continuation argument to be used instead of returning. As was
exposed by TODO:cite, SSA and CPS can be translated into each other.

We here present a translation of the GVN algorithm to CPS.

#Notations

A usual BNF grammar of CPS terms is:

\begin{equation}
\begin{array}{r l}
m ::= & f \: v_1 \: \dots \: v_n \: k\\
    | & l \: v_1 \: \dots \: v_n\\
    | & if(v) \: then \:
          l_1 \: v_1 \: \dots \: v_n \:
        else \:
          l_2 \: u_1 \: \dots \: u_n\\
    | & let \: x \: = \: v \: in \: m\\
    | & letrec \: \{ \Lambda_i | 0 < i < n \} \: in \: m\\
k ::= & l\\
    | & \lambda_c \: x \: \cdot \: m\\
\Lambda ::= & f \: = \: \lambda_j \: x_1 \: \dots \: x_n \: \cdot \: m\\
v, u ::= & x\\
       | & 0 \: | \: 1 \: | \: \dots\\
       | & v_1 \: + \: v_2\\
       | & v_1 \: \times \: v_2\\
       | & \dots\\
\end{array}
\end{equation}

##Different kinds of $\lambda$s

Note that $\lambda$s have annotation: either $c$ for continuations, $j$
for jumps, or $p$ for procedures. The BNF grammar presented here does not show
$\lambda_p$. This is because we only perform an intra-procedural optimisation.
Thus we are interested in terms that are bodies of $\lambda_p$.

The annotations are for compilation purpose:

- $\lambda_c$ are used as return points for function calls,
- $\lambda_j$ are to be translated as labels inside the same procedure, and
- $\lambda_p$ are for complete procedures.


##Lexical conventions

The following lexical convention are used in the document:

- $f$, $l$, $x$, and $y$ are variables, more specifically,
    + $f$ is used for global function ($\lambda_p$) calls,
    + $l$ is used for local function ($\lambda_j$) calls, and
    + $x$ and $y$ are used for non-$\lambda$ variables,
- $i$ for indices, and
- $n$ as arbitrary bounds for indexes.

We also consider that alpha-collisions have been taken care of.

##OCaml representation

The OCaml type for terms is:

\begin{verbatim}
type m =
  | Mapp  of (var * value list * continuation)
  | Mcont of (var * value list)
  | Mif   of (value * (var * var list) * (var * var list))
  | Mlet  of (var * value * m)
  | Mrec  of ((var * var list * m) list * m)
and continuation =
  | Cvar of var
  | C    of (var * m)
and value =
  | Vvar of var
  | Vcst of int
  | Vadd of (value * value)
  | Vmul of (value * value)
  | ..
\end{verbatim}

The notion of primitive operators (addition, multiplication) is purposedly
left unspecified.

##About SSA to CPS translation

Here is a correspondence table for SSA to and from CPS translation:

+----------------------+-------------------------+---------------------------+
| SSA                  | CPS                     | OCaml CPS                 |
+======================+=========================+===========================+
| Procedure            | Lambda ($\lambda_p$)    | `var * var list * m`      |
+----------------------+-------------------------+---------------------------+
| Basic Block          | See \ref{sec:about-b-b} | See \ref{sec:about-b-b}   |
+----------------------+-------------------------+---------------------------+
| Jump                 | Continuation Call       | `Mcont _`                 |
+----------------------+-------------------------+---------------------------+
| Procedure Call       | Application w/ Cont     | `Mapp (_, _, C _)`        |
+----------------------+-------------------------+---------------------------+
| Procedure Tail Call  | Application w/ Cont Var | `Mapp (_, _, Cvar _)`     |
+----------------------+-------------------------+---------------------------+
| Branch               | If-Then-Else            | `Mcond _`                 |
+----------------------+-------------------------+---------------------------+
| Return               | Continuation Call       | `Mcont _`                 |
+----------------------+-------------------------+---------------------------+

For reasons of scope, a basic block is translated as follows:

\begin{verbatim}
+----------+
| x1 <- v1 |     let x1 = v1 in
| x2 <- v2 |     let x2 = v2 in
|    ..    |     letrec { [dominatees] } in
|  <jump>  |     [<jump>]
+----------+
\end{verbatim}

Note in particular that the bindings of variables precede the bindings of
$\lambda$s.


###About dominators

It is also important to keep in mind that the dominance tree of the SSA CFG is
directly reflected in the term structure of the CPS term. More specifically,
when a block $b$ is the immediate dominator of $b_i$, the translation contains
$letrec \: \{ \Lambda_i \} \cup \_ \: in \: _ m$, where $m$ is the translation
of of $b$, and $\Lambda_i$ is the translation of $b_i$. (Note that $m$ might
be nested in another term, e.g. an `Mapp`.)

Note that this correspondance between the term structure and the dominator
tree is not necessary for terms to be valid (with respect to scoping and
well-formed-ness). We happen to preserve the dominator information during the
translation.


###About basic blocks

\label{sec:about-b-b}

The original GVN algorithm description did not treat procedure calls. While we
do account for them, we don't perform any smart optimisation (e.g. reordering)
with them. This is why we consider function calls as unmovable basic block
limits.

Hence a basic block ends with any application (be it conditional (`Mcond`),
direct (`Mcont`), or external (`Mapp`)). This means that basic blocks are
chunks of terms enclosed between a $\lambda$ and an application.

E.g. there are two basic-blocks in the following $\lambda_p$ (that computes $2
\times max(foo+1, bar+1)$ where $foo$ and $bar$ are the procedure argument's
and $max$ is implemented by another $\lambda_p$)

\begin{verbatim}
(main, [foo, bar],
  Mlet (x, Vadd(Vvar foo, Vconst 1),   //binding
  Mlet (y, Vadd(Vvar bar, Vconst 1),   //binding
  Mapp (max, [Vvar x, Vvar y], C (z,   //end-of-block
  Mlet (xx, Vmult (Vvar z, Vconst 2),  //binding
  Mcont (return, [Vvar xx])            //end-of-block
))))))
\end{verbatim}

The first block binds $x$, and $y$, the second binds $xx$. The binding of $z$
is not part of any block's bindings per-se.


##Notions

We always work in the context of a $\lambda_p$; that is,
\`\`$\exists m \text{ a term}$'' is to be understood as
\`\`$\exists m \text{ a term in the body of the current }\lambda_p$''

We define the following:

\begin{description}

\item[Subterms]: the the terms that can be found inside a term

\begin{equation}
\begin{array}{r r l}
Subterms:
  & m \: \mapsto & \{ m \} \cup StrictSubterms(m) \\
StrictSubterms:
  & f \: v_1 \: \dots \: v_n \: k \: \mapsto & Subterms_k(k) \\
  & l \: v_1 \: \dots \: v_n \: \mapsto & \{ \} \\
  & if(\_) \: then \: \_ \: else \: \_ \: \mapsto & \{ \}\\
  & let \: x \: = \: v \: in \: m \: \mapsto & Subterms(m) \\
  & letrec \: \{ \Lambda_i | 0 < i < n \} \: in \: m \: \mapsto & Subterms(m) \cup \bigcup_{0 < i < n} Subterms_{\Lambda}(\Lambda_i)\\
Subterms_k:
  & l \: \mapsto & \{ \} \\
  & \lambda_c \: x \: \cdot \: m \: \mapsto & Subterms(m) \\
Subterms_{\Lambda}:
  & f \: = \: \lambda_j \: x \: \dots \: x_{n} \: \cdot \: m \: \mapsto & Subterms(m)\\
\end{array}
\end{equation}

\begin{verbatim}
let rec subterms t = match t with
  | Mapp  (_, _, Cvar _     ) -> [t]
  | Mapp  (_, _, C    (_, m)) -> t :: subterms m
  | Mcont (_, _) -> [t]
  | Mif   (_, (_, _), (_, _)) -> [t]
  | Mlet  (_, _, m) -> t :: subterms m
  | Mrec  (ls, m) ->
    t :: subterms m @ List.flatten (List.map (fun (_, _, m) -> subterms m) ls)
\end{verbatim}

\item[Calls]: the calls that are made in a CPS term

\begin{equation}
\begin{array}{r l}
Calls(f \: v_1 \: \dots \: v_n \: k) = & Calls_k(k) \\
Calls(l \: v_1 \: \dots \: v_n) = & \{ l \} \\
Calls(if(v) \: then \: l_1 \: v_1 \: \dots \: v_n \: else \: l_2 \: u_1 \: \dots \: u_n) = & \{ l1, \: l2 \}\\
Calls(let \: x \: = \: v \: in \: m) = & \{ \} \\
Calls(letrec \: \{ \_ \} \: in \: m) = & \{ \}\\
Calls_k(l) = & \{ l \} \\
Calls_k(\lambda_c \: x \: \cdot \: m) = & \{ \} \\
\end{array}
\end{equation}

\begin{verbatim}
let rec calls = function
  | Mapp  (_, _, Cvar k) -> [k]
  | Mapp  (_, _, C    _) -> []
  | Mcont (k, _) -> [k]
  | Mif   (_, (k1, _), (k2, _)) -> [k1; k2]
  | Mlet  (_, _, _) -> []
  | Mrec  (_, _) -> []
\end{verbatim}

Note that we assume that names are unique (and thus that a function and its
name can be associated). This is a cheap assumption because the context
ensures that functions are named after SSA block labels (which need be
unique).

We naturally extend $Calls$ to apply on sets. This is useful for composing
$Calls$ and $Subterms$ to get all the calls of a term.


\item[Conditional] tests wheter a term is a conditional

\begin{equation}
\begin{array}{l}
Conditional(m) = True \text{ if } m = if(\_) \: then \: \_ \: else \: \_ \\
Conditional(m) = False \text{ otherwise}
\end{array}
\end{equation}

\item[Terminator]

\begin{equation}
\begin{array}{r c c l}
Terminator:
  & m & \mapsto & m \text{ if } \left\{
    \begin{array}{c}
      m = f \: v_1 \: \dots \: v_n \: \_ \text{ or} \\
      m = l \: v_1 \: \dots \: v_n \text{ or} \\
      m = if(v) \: then \: l_1 \: v_1 \: \dots \: v_n \: else \: l_2 \: u_1 \: \dots \: u_n \\
    \end{array} \right. \\
  & let \: \_ \: = \: \_ \: in \: m & \mapsto & Terminator(m) \\
  & letrec \: \{ \_ \} \: in \: m & \mapsto & Terminator(m) \\
\end{array}
\end{equation}

\item[Siblings]: $\lambda$s of the same parent

$Siblings(\Lambda) = L$ such that
$letrec \: L \: in \: m'$ is a term and $\Lambda \in L$

\item[StrictSiblings]:

$StrictSiblings(\Lambda) = Siblings(\Lambda) - \Lambda$



\item[Head]: the name of the continuation a term is the body of

\begin{equation}
\begin{array}{l}
Head(m) = f \Leftrightarrow
  Parent(m) =
    let \: rec \: \dots \:
           and \: f \: = \: \lambda_j \: \_ \: \cdot \: m \:
           and \: \dots \:
    in \: \_ \\
Head(m) \text{ is undefined otherwise}
\end{array}
\end{equation}


\item[Body]: the inverse of $Head$

$Body(f) = m \Leftrightarrow f = Head(m)$

\item[Variables]: all the variables appearing in a value

\begin{equation}
\begin{array}{r l}
Variables :
  & x \mapsto \{ x \}\\
  & 0 \mapsto \{\}, \: 1 \mapsto \{\}, \: \dots \\
  & v_1 \: + \: v_2 \mapsto \{v_1, v_2\} \\
  & v_1 \: \times \: v_2 \mapsto \{v_1, v_2\} \\
  & \dots\\
\end{array}
\end{equation}

\end{description}


#GVN on CPS

##Code Modifications

Just as with the original GVN algorithm, the code needs to be (automatically)
modified. The two modifications that we apply are:

- landing lambdas insertion with virtual call annotations, and
- trivial-call uninlining.

### Landing Lambdas

GVN introduces landing pads at the entrance of each loop. These nodes allow to
move code from \`\`after'' the loop to \`\`before'' it. We call the
corresponding concept in CPS *landing lambdas*.

\begin{description}
\item[Simple loop]

A \em{simple loop} is a term $m$ such as

\begin{equation}
\begin{array}{r l}
Head(m) \in Calls(m) & \\
\forall f \in Calls(m), & f \in Head(Subterms(m) \text{ or} \\
                        & Head(m) \notin Calls(Body(f)) \text{ and transitively} \\
\end{array}
\end{equation}

\item[Simple loop head]

A simple-loop head is the $Head$ of a simple-loop

\texttt{l} is a simple loop head when it is part of

\begin{verbatim}
let rec simple_loop_headers = function
  | Mapp  (_, _, Cvar _     ) -> []
  | Mapp  (_, _, C    (_, m)) -> simple_loop_headers m
  | Mcont (_, _) -> []
  | Mif   (_, (_, _), (_, _)) -> []
  | Mlet  (_, _, m) -> simple_loop_header m
  | Mrec  (ls, m) ->
    simple_loop_headers m
    :: List.fold_left
         (fun a (l, _, m) -> if List.mem l (calls m) then l :: a else a)
         []
         ls
\end{verbatim}

\end{description}


Simple loop headers are the entry nodes of loops that have exactly one entry
node. This, however, is not sufficient to treat all the loop cases. Consider
for example of mutually recursive functions.

\begin{verbatim}
let rec even x b =
  if x = 0 then b else odd (x - 1) (not b)
and odd x b =
  if x = 0 then not b else even (x - 1) (not b)
in ..
\end{verbatim}

In case these recursive functions are tail-recursive (as is the case
here) compiling the functions as $\lambda_j$ rather than $\lambda_p$ will
yield better results (in term of stack usage and execution time). However, the
call pattern of these $\lambda$ do not fit in the pattern of a simple loop.

A more complete definition for loops is as follows.

\begin{description}
\item[Loop]

$(L, E ,C)$ is a \em{loop} of $m$ if $L$, $C$, and $E$ are maximal sets of
$\Lambda$ such that

\begin{equation}\label{loopdef:0}
  L \supseteq E \supseteq C
\end{equation}
\begin{equation}\label{loopdef:1}
  m = letrec \: Siblings(L) \: in \: m'
\end{equation}
\begin{equation}\label{loopdef:2}
  \begin{array}{r l}
    \forall \Lambda, \Lambda' \in L \: \exists \Lambda_0, \dots, \Lambda_n \in L \text{ such that } &
      \Lambda = \Lambda_0, \: \Lambda' = \Lambda_n, \text{ and} \\
    & \forall i < n \: Calls(Subterms_{\Lambda}(\Lambda_i)) \ni \Lambda_{i+1} \\
  \end{array}
\end{equation}
\begin{equation}\label{loopdef:3}
  ((Calls(Subterms(m')) \cup Calls(Subterms_{\Lambda}(StrictSiblings(L))))) \cap L = E \neq \{\}
\end{equation}
\begin{equation}\label{loopdef:4}
  \begin{array}{r l}
    \forall \Lambda \in C
      & Conditional(Terminator(\Lambda)) \\
      & Calls(Subterms(\Lambda)) \cap L \neq \{\} \\
      & Calls(Subterms(\Lambda)) \cap StrictSiblings(L) \neq \{\} \\
    \end{array}
\end{equation}

\end{description}

Elements of $L$ are all siblings \eqref{loopdef:1} with a complete looping
call graph \eqref{loopdef:2}. Elements of $E$ are entry points to the loop
\eqref{loopdef:3}, that is, they are called from the other sub-terms of $m$.
Elements of $C$ are entry $\Lambda$ that double as exit $\Lambda$
\eqref{loopdef:4}, we call them $entry\text{-}exit$ or $conditional$
$\Lambda$s

The maximality condition is important so as to capture the whole loop.


Introducing Landing Lambdas is achieved by transforming a term in the
following fashion:

\begin{description}
\item[Landing-Lambdas]
if $t = letrec \: L \sqcup M \: in \: m$ has a loop $(L, E ,C)$, then

\begin{equation}
LandingLambda(t) = letrec \: \{ \Lambda \} \cup M \: in \: m'
\end{equation}

where
\begin{equation}
\begin{array}{r l l}
\Lambda & = & pad = \lambda \: i \: args \: \cdot \: letrec \: L \cup C' \: in \: m'' \\
pad & & \text{is a fresh label} \\
args & & \text{is the union of arguments of elements of } E \\
C' & = & C[l = \lambda \: args \: \cdot \: m \: / \: l_{cpad} = \lambda \: args \: \cdot \: m] \\
m'' & = & letrec \: \{ Dispatch_2 \} \: in \: if (i = 1) \: then \: CallTo(\Lambda_1) \: else \: dispatch_2 \: i \\
Dispatch_i & = & dispatch_i \: = \: \lambda \: j \: \cdot \: letrec \: \{ Dispatch_{i+1} \} \: in if(j=i) \: then CallTo(\Lambda_i) \: else \: dispatch_{i+1} k \\
\iota & : & l \rightarrow [ 1, Card(E) ] \text{ injective} \\
\iota & : & \text{undefined if } l \notin E \\
CallTo(l = \lambda \: vs \: \cdot \: m) & = & l_{cpad} \: vs \text{ if } l \in C \\
CallTo(l = \lambda \: vs \: \cdot \: m) & = & l \: vs \text{ otherwise} \\
m' & = & m[l \: v_1 \: \dots \: v_n \: / \: pad \: \iota(l) \: v_1 \: \dots \: v_n \: 0 \: \dots \: 0 ]_{l \in E}
\end{array}
\end{equation}

\end{description}

Note however that such a definition requires the extraction of maximal cliques
(which is not easy).

<!--TODO: better explanation of dispatch terms -->

The \`\`union of arguments'' can be implemented in different ways. The
prototype uses $max(numberOfArgs(E)$ fresh variables. The $0$s in $m'$ are
padding to adapt for the potentially higher number of arguments.

The GVN algorithm was specifically designed for SSA programs and direct
manipulation of the CFG. The CPS equivalent for which is the call graph. It
can be obtained with a one-pass traversal of a CPS term. This additional
difficulty—as well as the loop definition incompleteness—shows that the
algorithm was originally designed for a specific goal.



####Landing-$\lambda$s and Trampolines

A trampoline is a trick using a high-level calling convention to implement
tail call optimisation on a low-level target that does not support it. (E.g.
`ocamljs`, an OCaml compiler targeting Javascript.)

The Landing-$lambda$ transformation differs from a trampoline insertion in
that trampolines require change to every call to the bounced functions, while
landing-$\lambda$s only affect calls from the outside of the loop.


####Virtual calls annotations

When this transformation is performed, virtual calls can be added to the
call graph. These additional vertices allow the move of code from \`\`after''
the loop to \`\`before'' the loop.

The set of virtual edges is

\begin{equation}
VirtualCalls =
  \bigcup_{L \in Loops}
    \{(l, e) |
      l \text{ is the landing $\lambda$ of $L$} \text{ and }
      e \in Calls(Subterms_{\Lambda}(L)) - Head(Subterms_{\Lambda}(L))
    \}
\end{equation}


###Trivial-call Uninlining

In this transformation we add a level of indirection to some calls by
un-inlining a trivial redirection. This allows the moving of code to the
trivial $\lambda$ (that becomes non-trivial) just like edge splitting does in
SSA.

\begin{description}
\item[Uninline]

\begin{equation}
\begin{array}{r l}
Uninline_{true}(if(v) \: then \: l_1 \: vs \: else \: l_2 \: us ) = &
  letrec \: \{ f \: = \: \lambda \: () \: \cdot \: l_1 \: vs \: \} \: in \:
    if(v) \: then \: f \: () \: else \: l_2 \: us \\
Uninline_{false}(if(v) \: then \: l_1 vs \: else \: l_2 \: us) = &
  letrec \: \{ f \: = \: \lambda \: () \: \cdot \: l_2 \: us \: \} \: in \:
    if(v) \: then \: l_1 \: vs \: else \: f \: () \\
\end{array}
\end{equation}

\item[Needs uninlining]
Considering the term
$letrec \: \{ \Lambda_c, \: \Lambda_t \} \cup L \: in \: m$, $c$ needs
uninlining if

\begin{equation}
\begin{array}{l}
\begin{array}{r l l}
c \in Subterms_{\Lambda}(\Lambda_c) & \text{such as} & Conditional(c) \\
                                    &                & Calls(c) \ni \Lambda_t \\
\end{array} \\
Calls(m) \cup Calls_{\Lambda}(L) \ni \Lambda_t
\end{array}
\end{equation}

\end{description}

<!--TODO: treat the case where the other part (m) is the conditional -->

Once again the call graph is needed in order to detect the terms that need to
be tampered with.


##Values Ranking

Adapting the ranking system from the original GVN algorithm is quite straight
forward.


\begin{description}
\item[$rank$]
is defined as follows

\begin{equation}
\begin{array}{r l}
rank :
  & 0 \: \mapsto \: 0, \: 1 \: \mapsto \: 0, \: \dots \\
  & v_1 \: op \: v_2 \: \mapsto \: 1+max(rank(v_1), rank(v_2)) \\
  & x \: \mapsto \: 1+max(rank(v_1),\dots,rank(v_n)) \text{ if } f \: v_1 \: \dots \: v_n \: \lambda_c \: x \: \cdot \: \_ \\
  & x \: \mapsto \: rank(v) \text{ if } let \: x \: = \: v \: in \: \_ \\
  & v \: \mapsto \: 0 \text{ if $v$ is a $\lambda_p$ parameter} \\
  & v \: \mapsto \: max(r_1,\dots,r_n) \text{ if $v$ is a $\lambda_j$ parameter called with values of rank $r_i$} \\
\end{array}
\end{equation}

\end{description}

Note that ranks are not always well defined. Consider the following term
(where free variables are supposed to have been defined in the enclosing
term).

\begin{align*}
&letrec \{ \\
&\:\: f_1 \: = \: \lambda_j \: x_1 \: o_1 \: \cdot \: test_1 \: o_1 \: (\lambda_c \: b_1 \: \cdot \: if(b_1) \: then \: f_2 \: (x_1+1) \: b_1 \: else \: exit \: x_1) \:, \\
&\:\: f_2 \: = \: \lambda_j \: x_2 \: o_2 \: \cdot \: test_2 \: o_2 \: (\lambda_c \: b_2 \: \cdot \: if(b_2) \: then \: f_1 \: (x_2+1) \: b_2 \: else \: exit \: x_2) \:, \\
&\} \: if(b_0) \: then f_1 \: v_1 \: w_1 \: else f_2 \: v_2 \: w_2 \\
\end{align*}

The ranks for $x_1$ and $x_2$ are:

\begin{equation}
\begin{array}{l}
rank(x_1) = max(rank(x_2), rank(v_1)) \\
rank(x_2) = max(rank(x_1), rank(v_2)) \\
\end{array}
\end{equation}

This means that any value grater than $max(rank(v_1),rank(v_2))$ is okay. In
such a case, we take the rank to be the minimal acceptable rank. This is
equivalent to defaulting unavailable ranks to zero (as was done in the
original algorithm). Defaulting to zero is essentially the same as not taking
(mutually) recursive calls into account.


##Trivial Binding Removing

Removing some trivial bindings in CPS code is easier than removing the
corresponding trivial assignements in SSA form. Because of the scoping rule,
changes are local to a term. On the other hand, the term structure is not as
nice to work upon as a block of—temporarily unordered—assignments because it
is more rigid.

Thus we change the $let-in$ construct of our CPS terms. This is only intended
to be used localy and does not need to be exported outside of this
optimisation. (That is, it can be converted back to classic CPS after the
optimisation is done.)

\begin{equation}
\begin{array}{r c l}
m & -::= & let \: x \: = \: v \: in \: m\\
m & +::= & letand \: \{ (x_i, v_i) | 0 < i < n \} \: in \: m\\
\end{array}
\end{equation}

Not all $letand-in$ bindings are tolerated:

\begin{description}
\item[$letand$ well formed-ness]

\begin{equation}
\begin{array}{c}
letand \: \{ (x_i, v_i) | 0 < i < n \} \: in \: m \text{ is well formed } \\
\iff \\
\forall \: 0 < i, j < n \: x_i \notin Variables(v_j)
\end{array}
\end{equation}

\end{description}

It is possible to leverage ranks in order to make maximal (as big as
possible), well formed (but no bigger) $letand$ constructs. Essentially, in
each *binding strand* of a term, the variables of identical ranks are
coalesced together into one $letand$. Those are then sorted by ranks so as to
guarantee correct scoping.

Two bindings are in the same strand if they are in an equivalence class for
the reflexive, symmetric, transitive closure of the following relation:

$(x_1, m_1) R (x_2, m_2) \iff let \: x_1 \: = \: m_1 \: in \: let \: x_2 \: = \: m_2 \: in \: \_$

There are good reasons not to include application-continuation style bindings
(those obtained via `Mapp (_, _, C (x, _))`):

- the binding is not to an expression, and
- function call order should be preserved.

Once this transformation has been performed it is possible to remove trivial
assignments.


\begin{description}
\item[Trivial Binding Removal]

\begin{equation}
\begin{array}{r l}
letand \: \{ (x, y) \} \cup B \: in \: m \: \mapsto & letand \: B[x/y] \: in \: m[x/y] \\
letand \: \{ (x_1, y_1 \: op \: y_2), (x_2, y_1 \: op \: y_2) \} \cup B \: in \: m \: \mapsto & letand \:  \{ (x_1, y_1 \: op \: y_2), (x_2, x_1) \} \cup B \: in \: m \\
\end{array}
\end{equation}

\end{description}

Note that both rules can lead to the other rule being applicable. Thus the
transformation needs to be run until a fix-point is reached. In order to bound
the complexity of this operation, one can accumulate the substitutions that
needs to be performed on $m$ while searching for a fix-point on the bindings;
and apply them in one go after the fix-point has been reached. Substituting on
$m$ is potentially costly due to unpredictably deep recursion.

In the original GVN algorithm, trivial $\phi$ assignments
($v \leftarrow \phi(w, w)$ and $v \leftarrow \phi(v, w)$) are also simplified.
This translates in CPS as a removal of parameters that are always instantiated
with the same variables.



##Folding

The main part of the original algorithm is a nested loop over ranks (starting
at $0$) and blocks (in top-sort order from the \`\`deepest'' to the
\`\`shallowest''). Each execution of the body of the loop leads to potential
trivial assignments. Thus, it is necessary to interleave the trivial
assignment removal The body of the loop consists in:

(a) moving computations from either
    (1) the deeper block the current one jumps to, or
    (2) the two deeper blocks the current one conditionally jumps to, and
(b) marking movable computations as such

Both actions are handled differently depending on the nature of the node in
focus: landing-pad, loop header, or normal.

###Traversal

In this CPS version, we can replace top-sort order by:

- do sub-terms before yourself
- do sub-terms in 'calls' order (that is, start with callees, end with
  callers)

When the 'calls' order is not defined, we are in a loop. In this particular
case, the transitive closure of the call graph is a clique and the traversal
order can be simplified to \`\`sub-terms before self''. Note that these blobs
of unordered $\Lambda$s are isolated under a landing-$\lambda$.

Before dwelling into folding, we present an updated version of our OCaml
representation.

\begin{verbatim}
type m =
  | Mapp  of (var * value list * continuation)
  | Mcont of (var * value list)
  | Mif   of (value * (var * var list) * (var * var list))
  | Mbind of ((int * (var * value) list) list * m) (* [rank, [binding]] *)
  | Mlambda of ((var * var list * m) list * m)
  | Mloop   of (var * var list * (var * var list * m) list * m * m)
and continuation =
  | Cvar of var
  | C    of (var * m)
and value =
  | Vvar of var
  | Vcst of int
  | Vadd of (value * value)
  | Vmul of (value * value)
  | ..
\end{verbatim}

(`Mloop (v, vs, ls, m1, m2)` is to be understood as `Mrec ([v, vs, Mrec (ls,
m1)], m2)` where `ls` is a loop.)


The following invariants are to be maintained:

- in `Mlambda`, the bindings are sorted in callees-before-callers order
- in `Mlambda` (resp `Mloop`) the term (`m` (resp. `m2`)) is a terminator
  (this avoids rank interleaving)
- in `Mloop (v, vs, ls, dispatch, m)`,
    + `dispatch` only makes call to elements of `ls`,
    + `m` does not call `ls` directly, it calls `v` instead,
- no two `Mbind` can be nested directly
    + i.e. `Mbind (_, Mbind _)` is forbidden (but `Mbind (_, Mapp (_, _, C (_,
      Mbind _)))` is okay)
- in `Mbind` only one batch of bindings *per rank* is allowed,
- no `Mbind` is empty (`Mbind ([], _)`) nor is any rank (`Mbind ([…; (r, []);
  …], _)`

(Note: these invariants are not necessary. They make the folding easier
however.)

The traversal is performed as follows:

\begin{verbatim}
TODO
\end{verbatim}

Note that:

- `mark` returns a (marked but otherwise untouched) term.
- the code above is written in a partially imperative style: the `get_movable`
  and `get_movable_br` functions are supposed to remove the bindings they
  return.
- the code is incomplete regarding the treatment of landing-$\lambda$s and
  loop headers.

While the first remark can be taken care of by maintaining a marking-table
outside of the term, the other remarks call for a change in the type of terms.
Using a different constructor for landing-$\lambda$s and other lambdas makes
sense.

###Post folding operations

After folding, it is necessary to come back to the original CPS term
representation. This is acheived by replacing `Mbind` constructors with `Mlet`
ones. The invariant property of ranks makes it an easy task. TODO: a little
more details.

The algorithm can introduce \`\`empty'' terms. E.g. landing-$lambda$s might
not have received any bindings from nodes that are \`\`after'' the loop. In
this case the offending nodes can simply be removed.


\begin{description}
\item[Empty nodes removal]

\begin{equation}
\begin{array}{r l}
letrec \: \{ f = \lambda_j \: \_ \cdot l \_ \} \cup L \: in \: m \: \mapsto &
  (letrec \: L \: in \: m)[f \: \_ / \: l \_] \\
letrec \: \{\} \: in \: m \mapsto & m
\end{array}
\end{equation}

\end{description}


